{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is python : True\n",
      "module://ipykernel.pylab.backend_inline\n",
      "cpu\n",
      "Number of actions : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "from itertools import count\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "# создаем энвайронмент с игрой\n",
    "env = gym.make('Breakout-v0').unwrapped\n",
    "\n",
    "# настраиваем matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display    \n",
    "print(\"Is python : {}\".format(is_ipython))\n",
    "print(matplotlib.get_backend())\n",
    "\n",
    "# выбираем девайс для игры\n",
    "# device = torch.device('cuda:%d' % 3)\n",
    "# print(\"Device : {}\".format(device))\n",
    "# torch.cuda.set_device(3)\n",
    "device = torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "# запоминаем, сколько действий в игре\n",
    "ACTIONS_NUM = env.action_space.n\n",
    "print(\"Number of actions : {}\".format(ACTIONS_NUM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SIZE = 4\n",
    "STATE_W = 84\n",
    "STATE_H = 84\n",
    "MEMSIZE = 50000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 1. Необходимо реализовать класс для хранения состояния игры. \n",
    "# В качестве последнего мы будем использовать состеканные 4 последовательных кадра игры.\n",
    "# Это необходимо, чтобы агент понимал скорости и ускорения игровых объектов.\n",
    "\n",
    "\n",
    "class StateHolder:\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(StateHolder, self).__init__()\n",
    "        self.state = torch.zeros(1,STATE_SIZE,STATE_W,STATE_H)\n",
    "        self.state = self.state.to(device).byte()      \n",
    "\n",
    "\n",
    "        \n",
    "    def get(self):\n",
    "        return self.state\n",
    "    \n",
    "    def push(self, batch):\n",
    "        self.state = self.state.to(device).byte()        \n",
    "        self.state = torch.squeeze(self.state)\n",
    "        self.state = self.state[1::]\n",
    "        self.state = torch.cat((self.state,batch),0)\n",
    "        self.state = torch.unsqueeze(self.state,0)\n",
    "        \n",
    "\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = torch.zeros(1,STATE_SIZE,STATE_W,STATE_H)\n",
    "        self.state = self.state.to(device).byte()         \n",
    "\n",
    "\n",
    "\n",
    "# class StateHolder: \n",
    "#     def __init__(self): \n",
    "#         self.stack=0 \n",
    "#         self.tmp = [] \n",
    "#         self.len=0 \n",
    "\n",
    "#     def push(self, screen): \n",
    "#         if(self.len==0): \n",
    "#             self.tmp = [screen]*4 \n",
    "#             self.stack=torch.stack(self.tmp,1) \n",
    "#             self.len = 1 \n",
    "#         else: \n",
    "#             self.tmp.append(screen) \n",
    "#             self.stack=torch.stack(self.tmp[-4:],1) \n",
    "\n",
    "\n",
    "#     def get(self): \n",
    "#         return self.stack.to(device).byte() \n",
    "\n",
    "#     def reset(self): \n",
    "#         self.stack=0 \n",
    "#         self.tmp = [] \n",
    "#         self.len=0\n",
    "    \n",
    "    \n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory:\n",
    "\n",
    "    def __init__(self, capacity = MEMSIZE):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        #Положить переход в память\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        #Получить сэмпл из памяти\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 2. Собрать архитектуру сети (DQN).\n",
    "# В качестве примера можно использовать сеть вида:\n",
    "# Conv(4->32) -> Conv(32->64) -> Conv(64->64) -> FC(512) -> FC(ACTIONS_NUM)\n",
    "# В качестве функций активации необходимо использовать ReLU(но совершенно не обязательно ими ограничиваться)\n",
    "# Attention : не забудьте правильно инициализировать веса, это важно для данной задачи!\n",
    "class DQN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(DQN, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4)\n",
    "#             self.bn1 = nn.BatchNorm2d(32)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "#             self.bn2 = nn.BatchNorm2d(64)\n",
    "            self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "#             self.bn3 = nn.BatchNorm2d(64)\n",
    "            self.head = nn.Linear(3136, 512)\n",
    "            self.head2 = nn.Linear(512,4)\n",
    "            self.relu = nn.LeakyReLU()\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                    m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                    if m.bias is not None:\n",
    "                        m.bias.data.zero_()\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    m.weight.data.fill_(1)\n",
    "                    m.bias.data.zero_()\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    torch.nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.float()\n",
    "            x = self.relu(self.conv1(x))\n",
    "            #x = F.relu(self.conv1(x))\n",
    "            x = self.relu(self.conv2(x))\n",
    "            #x = F.relu(self.conv2(x))\n",
    "            x = self.relu(self.conv3(x))\n",
    "            #x = F.relu(self.conv3(x))\n",
    "            return self.head2(self.head(x.view(x.size(0), -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Тут блок с кодом, генерирующим 1 кадр игры\n",
    "# Обратите внимание, что выходным тензора является torch.ByteTensor со значениями 0-255\n",
    "# Это сделанно намеренно для экономии места(4х экономия по сравнению с FloatTensor)\n",
    "# Подумайте, где и как необходимо совершать преобразование ByteTensort -> FloatTensor, чтобы его можно было подавать в сеть. \n",
    "\n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize( (STATE_W, STATE_H), interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render(mode='rgb_array')\n",
    "    screen = np.dot(screen[...,:3], [0.299, 0.587, 0.114])\n",
    "    screen = screen[30:195,:]\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.uint8).reshape(screen.shape[0],screen.shape[1],1)\n",
    "    return resize(screen).mul(255).type(torch.ByteTensor).to(device)#.detach()\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().reshape(-1,84).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Далее стандартный метод для выбора нового действия из лекции\n",
    "\n",
    "policy_net = DQN().to(device)\n",
    "target_net = DQN().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=1e-4)\n",
    "\n",
    "memory = ReplayMemory()\n",
    "state_holder = StateHolder()\n",
    "\n",
    "def select_action(state, eps_threshold):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(ACTIONS_NUM)]], device=device, dtype=torch.long)\n",
    "\n",
    "train_rewards = []\n",
    "\n",
    "mean_size = 100\n",
    "mean_step = 1\n",
    "\n",
    "def plot_rewards(rewards = train_rewards, name = \"Train\"):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(rewards)\n",
    "    # Строим график среднего вознаграждения по 100 последним эпизодам\n",
    "    if len(rewards) > mean_size:\n",
    "        means = np.array([rewards[i:i+mean_size:] for i in range(0, len(rewards) - mean_size, mean_step)]).mean(1)\n",
    "        means = np.concatenate((np.zeros(mean_size - 1), means))\n",
    "        plt.plot(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Еще немного методов из лекции\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    # выбираем новый батч\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Для всех состояний считаем маску не финальнсти и конкантенируем их\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Считаем Q(s_t, a) - модель дает Q(s_t), затем мы выбираем\n",
    "    # колонки, которые соответствуют нашим действиям на щаге\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Подсчитываем ценность состяония V(s_{t+1}) для всех последующмх состояний.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device).detach()\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach() # берем значение максимума\n",
    "    \n",
    "    # Считаем ожидаемое значение функции оценки ценности действия  Q-values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Считаем ошибку Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    \n",
    "    # Оптимизация модели\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    \n",
    "    del non_final_mask\n",
    "    del non_final_next_states\n",
    "    del state_batch\n",
    "    del action_batch\n",
    "    del reward_batch\n",
    "    del state_action_values\n",
    "    del next_state_values\n",
    "    del expected_state_action_values\n",
    "    del loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество эпизодов, которые играем\n",
    "NUM_EPISODES = 100000\n",
    "TEST_EPS = 0.05\n",
    "# количество кадров, между которыми обучаем модель\n",
    "OPTIMIZE_MODEL_STEP = 5\n",
    "# количество кадров, между которыми обновляем target-модель\n",
    "TARGET_UPDATE=10000\n",
    "\n",
    "# несколько шагов для разогрева модели()\n",
    "STEPS_BEFORE_TRAIN = 50000\n",
    "\n",
    "# параметры для e-greedy стратегии выбора действия\n",
    "EPS_START = 1\n",
    "EPS_END = 0.1\n",
    "EPS_DECAY = 1000000\n",
    "\n",
    "policy_net.train()\n",
    "target_net.eval()\n",
    "\n",
    "state_holder = StateHolder()\n",
    "test_rewards = []\n",
    "\n",
    "# Общее число \n",
    "steps_done = 0\n",
    "eps = EPS_START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/100000 [00:00<14:37:08,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode score : 0.0\n",
      "Mean score : 0.0\n",
      "0.9998506123995139 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/100000 [00:01<15:09:24,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode score : 0.0\n",
      "Mean score : 0.0\n",
      "0.9996922526278003 343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/100000 [00:01<16:27:27,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode score : 1.0\n",
      "Mean score : 0.3333333333333333\n",
      "0.9994988395861323 558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bf8e89dfe7d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Шаг одного кадра игры\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mep_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Задание 3. Заполнить пропуски в нижеприведенном коде.\n",
    "\n",
    "for e in tqdm.tqdm(range(NUM_EPISODES)):\n",
    "    \n",
    "    # Инициализации разлинычх переменных\n",
    "    # env - среды\n",
    "    # state_holder - хранителя состояния\n",
    "    # lives - количества жизней в начале эпизода игры (Важно!)\n",
    "    env.reset()\n",
    "    state_holder.reset()\n",
    "    state_holder.push(get_screen())\n",
    "    state = state_holder.get()\n",
    "    lives = 5    \n",
    "    ep_rewards = []\n",
    "    print(eps, steps_done)\n",
    "    for t in count():\n",
    "        \n",
    "        # Рассчет eps_threshold'а для e-greedy\n",
    "        eps = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "        # Шаг одного кадра игры \n",
    "        action = select_action(state, eps)\n",
    "        _, reward, done, info = env.step(action.item())\n",
    "        ep_rewards.append(reward)\n",
    "        reward = torch.tensor([reward], device = device)\n",
    "\n",
    "        \n",
    "        \n",
    "        if not done:\n",
    "            state_holder.push(get_screen())\n",
    "            next_state = state_holder.get()            \n",
    "            if info['ale.lives']!= lives:\n",
    "                lives = info['ale.lives']\n",
    "                memory.push(state,action , None, reward)\n",
    "            else:\n",
    "                memory.push(state,action , next_state, reward)\n",
    "        else:\n",
    "            next_state=None\n",
    "            memory.push(state,action , next_state, reward)\n",
    "            \n",
    "        steps_done += 1\n",
    "        state = next_state\n",
    "        # где:\n",
    "        # reward - награда, полученная в рамках последнего действия\n",
    "        # done - флаг окончания эпизода\n",
    "        # info - важная системная информация\n",
    "        \n",
    "        # Код обработки перехода\n",
    "        # Работа с ReplayMemory\n",
    "\n",
    "    \n",
    "        \n",
    "        # Задание 3.1. Необходимо дополниь код следующим трюком, который значительно\n",
    "        # улучшает сходимость обучения. В случае, если эпизод не закончился, но агент на \n",
    "        # очередном шаге потерял жизнь, то такой переход надо класть в ReplayMemory как финальный.\n",
    "        # При этом, необходимо далее продолжать эпизод игры, пока не получите done == True\n",
    "        # Тет самым вы научите агента понимать, что терять жизни по дороге - плохо.\n",
    "        \n",
    "        # Шаг оптимизации\n",
    "        if (steps_done > STEPS_BEFORE_TRAIN) and steps_done % OPTIMIZE_MODEL_STEP == 0:\n",
    "            optimize_model()\n",
    "        \n",
    "        # Шаг обновления target'сети\n",
    "        if steps_done % TARGET_UPDATE == 0:\n",
    "            print(\"Target net updated!\")\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "        # Код завершающий эпизод игры/обучения\n",
    "        if done:\n",
    "            train_rewards.append(np.sum(ep_rewards))\n",
    "            # Суммарный reward(не дисконтированный) за последний эпизод\n",
    "            print(\"Episode score : {}\".format(train_rewards[-1]))\n",
    "            # Средний reward по последним 100 эпизодам\n",
    "            print(\"Mean score : {}\".format(np.mean(train_rewards[-100:])))\n",
    "            \n",
    "            plot_rewards()\n",
    "            break \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQN()\n",
    "policy_net.load_state_dict(torch.load(\"./weights.txt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Тут код для тестирования.\n",
    "# Задание 4. Просто выполнить данную ячейку и проверить вашего агента, насколько он хорош !?\n",
    "\n",
    "TEST_EPS = 0.05\n",
    "\n",
    "def show_state(env, step=0, info=\"\"):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "#     plt.title(\"%s | Step: %d %s\" % (env.spec.id, step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "def select_action(state,eps_threshold):\n",
    "    global steps_done\n",
    "    eps_threshold = TEST_EPS\n",
    "    \n",
    "    steps_done += 1\n",
    "    sample = random.random()\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(ACTIONS_NUM)]], device=device, dtype=torch.long)\n",
    "\n",
    "policy_net.eval()\n",
    "env.reset()\n",
    "state_holder.reset()\n",
    "    \n",
    "state_holder.push(get_screen())\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "for i in count():\n",
    "    # Выбрать и выполнить нове действие\n",
    "    action = select_action(state_holder.get(), TEST_EPS)\n",
    "    _, reward, done, _ = env.step(action.item())\n",
    "    total_reward += reward\n",
    "    # Получаем новое состояние\n",
    "    if not done:\n",
    "        state_holder.push(get_screen())\n",
    "    else:\n",
    "        env.reset()\n",
    "        state_holder.reset()\n",
    "    show_state(env, i)\n",
    "    \n",
    "print(\"Total game reward : {}\".format(total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data.pickle', 'wb') as f:\n",
    "    pickle.dump(policy_net, f)\n",
    "with open('data2.pickle', 'wb') as f:\n",
    "    pickle.dump(target_net, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DQN' object has no attribute 'save_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a1c6ad1be4b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"policy_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DQN' object has no attribute 'save_weights'"
     ]
    }
   ],
   "source": [
    "policy_net.save_weights(\"policy_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DQN' object has no attribute 'toJSON'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-286e64dadfed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJSON\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/a.oleshko/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 518\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DQN' object has no attribute 'toJSON'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json = policy_net.toJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a.oleshko/anaconda3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type DQN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(policy_net, './policy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(policy_net.state_dict(), './weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
